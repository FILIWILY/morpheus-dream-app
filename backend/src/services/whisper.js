import FormData from 'form-data';
import fetch from 'node-fetch';

const WHISPER_URL = process.env.WHISPER_URL || 'http://localhost:8000';

/**
 * –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é Whisper
 * @param {Buffer} audioBuffer - –ë–∏–Ω–∞—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∞—É–¥–∏–æ —Ñ–∞–π–ª–∞
 * @param {string} language - –ö–æ–¥ —è–∑—ã–∫–∞ (ru, en, es, de, fr)
 * @returns {Promise<string>} - –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
 */
export async function transcribeAudio(audioBuffer, language = 'ru') {
  // Mock mode - skip actual transcription
  if (process.env.USE_MOCK_AI === 'true') {
    console.log(`[Whisper] üé≠ MOCK MODE: Skipping real transcription`);
    await new Promise(resolve => setTimeout(resolve, 1000)); // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è —Ä–µ–∞–ª–∏–∑–º–∞
    const mockText = "–ú–Ω–µ –ø—Ä–∏—Å–Ω–∏–ª—Å—è —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–π —Å–æ–Ω. –Ø —Å—Ç–æ—è–ª –Ω–∞ –±–µ—Ä–µ–≥—É –±–µ—Å–∫—Ä–∞–π–Ω–µ–≥–æ –æ–∫–µ–∞–Ω–∞ –∏ —Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –≤–æ–ª–Ω—ã. –í–¥—Ä—É–≥ –≤ –Ω–µ–±–µ –ø–æ—è–≤–∏–ª–∞—Å—å –±–æ–ª—å—à–∞—è –±–µ–ª–∞—è –ø—Ç–∏—Ü–∞, –æ–Ω–∞ –ª–µ—Ç–µ–ª–∞ –ø—Ä—è–º–æ –∫–æ –º–Ω–µ. –í —Ä—É–∫–∞—Ö —É –º–µ–Ω—è –±—ã–ª —Å—Ç–∞—Ä–∏–Ω–Ω—ã–π –∑–æ–ª–æ—Ç–æ–π –∫–ª—é—á.";
    console.log(`[Whisper] üé≠ MOCK: Returning mock transcription: "${mockText.substring(0, 50)}..."`);
    return mockText;
  }
  
  try {
    console.log(`[Whisper] Starting transcription. Language: ${language}, buffer size: ${audioBuffer.length} bytes`);
    console.log(`[Whisper] Target URL: ${WHISPER_URL}/v1/audio/transcriptions`);
    
    const formData = new FormData();
    formData.append('file', audioBuffer, {
      filename: 'audio.webm',
      contentType: 'audio/webm'
    });
    
    // Whisper –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å OpenAI API
    formData.append('language', language);
    formData.append('response_format', 'json'); // –∏–ª–∏ 'text', 'verbose_json'
    
    console.log(`[Whisper] Sending request... (this may take 3-6 min on first run while model downloads)`);
    
    // –î–ª–∏–Ω–Ω—ã–π timeout –¥–ª—è –ø–µ—Ä–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ (6 –º–∏–Ω—É—Ç –¥–ª—è small)
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), 6 * 60 * 1000); // 6 minutes
    
    const response = await fetch(`${WHISPER_URL}/v1/audio/transcriptions`, {
      method: 'POST',
      body: formData,
      headers: formData.getHeaders(),
      signal: controller.signal
    });
    
    clearTimeout(timeout);
    
    if (!response.ok) {
      const errorText = await response.text();
      console.error(`[Whisper] HTTP Error: ${response.status} - ${errorText}`);
      throw new Error(`Whisper API error: ${response.status} - ${errorText}`);
    }
    
    const result = await response.json();
    console.log(`[Whisper] ‚úÖ Transcription successful. Text: "${result.text?.substring(0, 100)}..."`);
    console.log(`[Whisper] ‚úÖ Text length: ${result.text?.length || 0} chars`);
    
    return result.text;
  } catch (error) {
    console.error('[Whisper] Transcription failed:', error);
    if (error.name === 'AbortError') {
      throw new Error('Whisper transcription timeout (6 minutes). Model might be loading for the first time.');
    }
    throw new Error(`Failed to transcribe audio: ${error.message}`);
  }
}

/**
 * –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∑–¥–æ—Ä–æ–≤—å–µ Whisper —Å–µ—Ä–≤–∏—Å–∞
 * @returns {Promise<boolean>}
 */
export async function checkWhisperHealth() {
  try {
    const controller = new AbortController();
    const timeout = setTimeout(() => controller.abort(), 5000);
    
    const response = await fetch(`${WHISPER_URL}/health`, {
      method: 'GET',
      signal: controller.signal
    });
    
    clearTimeout(timeout);
    return response.ok;
  } catch (error) {
    console.error('[Whisper] Health check failed:', error);
    return false;
  }
}

